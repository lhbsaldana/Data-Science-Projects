# -*- coding: utf-8 -*-
"""[ML] Saldana - Finals

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xkWqhzDippyPgqSwE6dSXqRdmxVuwMKS
"""



"""### What is Association Rule Mining

<p> 

*   also known as Market Basket Analysis 
*   Help discover relationships between independent relational databases
*   ARM is primarily used in retail (recommendation system) 

To simplify, the logic behind the association rule mining is if two/more items are frequently bought together, these items can be recommended to the customer when he buys one of these items  

Source: https://towardsdatascience.com/association-rules-2-aa9a77241654 
</p>

### ECLAT Algorithm

<p> 
Equivalence Class Clustering and Bottom-up Lattice Traversal Algorithm (ECLAT) 

Pros: 

*   faster than Apriori Algorithm 
*   uses depth-first search approach to discover association rules 
*   consumes less memory 

Cons: 
*   only uses support as its metrics for evaluating strength of association rule

</p>

Source: https://towardsdatascience.com/the-eclat-algorithm-8ae3276d2d17

##Import dataset and necessary modules
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
!pip install pyECLAT
import matplotlib.pyplot as plt
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')
dir_name = '/content/drive/MyDrive/Colab Notebooks/'
dataset = pd.read_csv(f"{dir_name}Groceries data.csv")
dataset.head(5)

"""##EDA """

dataset.shape

dataset.info() #outputs the column

dataset.describe()

year = dataset['year'].value_counts()
year

year.plot(kind="bar")
plt.title('Transactions per Year')
plt.show()

dataset['itemDescription'].nunique() #the store contains 167 products

top10= dataset['itemDescription'].value_counts().head(10)
top10

#displays the top 10 most sellable items that appears in dataset 
top10.plot(kind="pie",autopct='%1.1f%%',radius=2)

dataset.isna().sum() #displays the count of NaN values for each column

"""###Pre-processing"""

dataset['date'] = pd.to_datetime(dataset[['year', 'month', 'day']])
dataset

#.zip() pairs up member_number and date (1 transaction) and puts them in a list 
dataset['member_date'] = list(zip(dataset['Member_number'],dataset['date'].dt.date))
dataset['quantity'] = 1 
dataset

"""<p>
A purchase is defined by a combination of ID and date of purchase. The zip() does this pairing because it groups a member ID with his/her date of purchase. The pair is then converted into a list.

The new column named quantity implies that each row in the dataset contains 1 item purchased by a customer.

</p>
"""

transactions = dataset.groupby('member_date')['itemDescription'].aggregate(lambda x: ','.join(list(x))).reset_index()
transactions.head()

"""<p> The output above refers to the items bought by a customer on a specific date. For each transaction, the items purchased by that customer is joined by commas. So, we see the list of products for each transaction in the itemDescription column. Through this, redundancy is avoided and the number of rows is reduced to 14,963.

So, for row one, customer with ID 1000, bought 3 items (pastry, salty snack, and a whole milk) last June 24,2014.
</p>
"""

basket = pd.DataFrame(transactions['itemDescription'].to_list())
basket = basket[0].str.split(',', expand=True)
basket

"""<p>The basket dataframe is a more 
expanded visualization of the items bought by each customer on a specific date. 

</p>

##Implementation of ECLAT Algorithm
"""

from pyECLAT import ECLAT 
dataEclat = ECLAT(data=basket,verbose=True)

dataEclat.df_bin

"""<p>Dataframe of binary values. 1 means it is included in the transaction, 0 means it's not included. This is analogous to the bag of words approach in Naive Bayes Classifier. 

</p>

####Parameters for the ECLAT Algorithm 

<p> 

*   Minimum support – percentage of the overall items from the dataset
*   Minumum combinations – the minimum amount of items in the transaction 
*  Maximum combinations – the maximum amount of items in the transaction





</p>
"""

min_supp = 7/len(dataset) #the item should appear at least 7% in the dataset
min_combi = 2 #for each rule, we want it to have at least 2 items
max_combi = 2 #for each rule, we want it to have at most 2 items

rule_indices, rule_supports = dataEclat.fit(min_support=min_supp,
                                                 min_combination=min_combi,
                                                 max_combination=max_combi,
                                                 separator=' & ')

result = pd.DataFrame(rule_supports.items(),columns=['Item', 'Support'])
result.sort_values(by=['Support'],ascending = False)

"""<p> The results above displays the association rules generated from the ECLAT Algorithm sorted from least support value to greatest. The total generated rules are 2,880. </p> """

item_df = pd.DataFrame(result['Item'].to_list())
item_df[['Antecedents', 'Consequents']]=item_df[0].str.split('&', expand=True)
supp_series= pd.Series(result['Support'])
fin_results = pd.concat([item_df,supp_series],axis=1)
fin_results.rename(columns={ fin_results.columns[0]: "Itemsets" }, inplace = True)

fin_results.sort_values(by=['Support'],ascending = False)

"""<p> The results above displays the association rules with labels antecedents and consequents for each association rule.</p>

###Using instant food products as example
"""

rules_instant= fin_results[fin_results["Antecedents"].apply(lambda x: "Instant food products" in x)]
rules_instant.sort_values('Support', ascending=False)

"""<p>Since we have a lot of association rules generated for each product, it is a bit challenging to decide which items should be put together with that product. Hence, we just want to determine what are the top items that are frequently brought together with a product. Let us use instant foods as an example. 
 </p> 
"""

rules_support = rules_instant[rules_instant['Support'] >= rules_instant['Support'].quantile(q = 0.90)]
rules_support

"""<p> 
The results above show the items that belong in the top 10 percentile. This implies that soda and whipped/sour cream are the most popular items that customers would buy together with instant food products. 
</p> 
"""

import seaborn as sns

pivot_support = rules_instant.pivot(index='Antecedents', columns='Consequents', values='Support')

sns.set_context("talk")
plt.style.use('ggplot')
plt.subplots(figsize=(5,5))
sns.set()
ax = sns.heatmap(data=pivot_support, annot=True, fmt='.2f', cmap='YlGnBu', cbar=True)
plt.title("Items' Support Matrix", fontsize=16, y=1.02)
ax.set_xlabel("Consequents",fontsize=16)
ax.set_ylabel("Antecedents",fontsize=16)
plt.xticks(rotation=45)
plt.yticks(rotation=0)
plt.show()

"""<p> 
The illustration above shows that instant food products are popular to be purchased with whipped/sour cream and soda. 

The graph suggests that the store can make promos such as discounts on whipped/sour cream and soda when the customer buys an instant food product. In addition, the store can have buy 2 instant food products to get a free one packet of whipped/sour cream  or a free bundle of assorted vegetables. 

Through this analysis, the store can quickly offload inventory and hit sales targets faster by the end of the month or quarter. This can also help increase positive reviews because of free product offerings and attract new customers because the store has complimentary deals for a discounted price. 

</p>

References: 

*   Ganiyu, I. S. (2022, May 24). Market Basket Analysis in Data Mining Simplified 101 - Learn | Hevo. Hevo. https://hevodata.com/learn/market-basket-analysis-in-data-mining/#algoGarg

* A. (2018, September 3). Complete guide to Association Rules (1/2). Towards Data Science; Towards Data Science. https://towardsdatascience.com/association-rules-2-aa9a77241654

* Korstanje, J. (2021, September 29). The Eclat algorithm. Medium. https://towardsdatascience.com/the-eclat-algorithm-8ae3276d2d17

* Malik, U. (2018, August 9). Association Rule Mining via Apriori Algorithm in Python. Stack Abuse; Stack Abuse. https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/

* Xavier. (n.d.). Market Basket Analysis. Kaggle.com. https://www.kaggle.com/code/xvivancos/market-basket-analysis/report
"""